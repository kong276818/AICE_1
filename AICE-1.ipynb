{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3503128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. CSV 파일 불러오기\n",
    "df_4000TT = pd.read_csv('4000TT.csv')\n",
    "df_input = pd.read_csv('input.csv')\n",
    "\n",
    "# 2. 'machine_name'을 기준으로 병합\n",
    "merged_df = pd.merge(df_4000TT, df_input, on='machine_name')\n",
    "\n",
    "# 3. 'input' 컬럼만 추출하여 infoDF로 저장\n",
    "infoDF = merged_df[['input']]\n",
    "\n",
    "# 결과 확인\n",
    "print(infoDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 예시: infoDF에 Address 열이 있다고 가정\n",
    "# infoDF = pd.read_csv(\"your_file.csv\")  # 필요시 파일 로딩\n",
    "\n",
    "# 1. Address 열에서 행정동 추출 (보통 마지막 단어)\n",
    "infoDF['행정동'] = infoDF['Address'].str.split().str[-1]\n",
    "\n",
    "# 2. 행정동별 빈도 확인\n",
    "print(infoDF['행정동'].value_counts())\n",
    "\n",
    "# 3. 시각화 - countplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=infoDF, x='행정동', order=infoDF['행정동'].value_counts().index)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('행정동')\n",
    "plt.ylabel('빈도수')\n",
    "plt.title('행정동 분포')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Time_Driving (주행시간) 분포 시각화\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=infoDF, x='Time_Driving', kde=True)\n",
    "plt.title('주행시간(Time_Driving) 분포')\n",
    "plt.xlabel('Time_Driving')\n",
    "plt.ylabel('빈도수')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Speed_Per_Hour (평균속도) 분포 시각화\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=infoDF, x='Speed_Per_Hour', kde=True)\n",
    "plt.title('평균속도(Speed_Per_Hour) 분포')\n",
    "plt.xlabel('Speed_Per_Hour')\n",
    "plt.ylabel('빈도수')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ae8469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 데이터 개수 확인\n",
    "print(\"300 이상 속도 데이터 수:\", (infoDF['Speed_Per_Hour'] >= 300).sum())\n",
    "\n",
    "# 이상치 제거\n",
    "infoDF = infoDF[infoDF['Speed_Per_Hour'] < 300]\n",
    "\n",
    "# 결과 확인\n",
    "print(\"처리 후 데이터 수:\", len(infoDF))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 300 이상인 값은 300으로 바꾸기\n",
    "infoDF['Speed_Per_Hour'] = np.where(infoDF['Speed_Per_Hour'] >= 300, 300, infoDF['Speed_Per_Hour'])\n",
    "\n",
    "# 확인\n",
    "print(infoDF['Speed_Per_Hour'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903af4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건에 맞는 데이터 필터링\n",
    "infoDF = infoDF[\n",
    "    (infoDF['Speed_Per_Hour'] >= 10) & (infoDF['Speed_Per_Hour'] <= 300) &\n",
    "    (infoDF['Time_Driving'] >= 1) & (infoDF['Time_Driving'] <= 1000)\n",
    "]\n",
    "\n",
    "# 결과 확인\n",
    "print(\"조건 적용 후 데이터 수:\", len(infoDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70efc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 스케일러 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 정규화 수행 및 새로운 컬럼 추가\n",
    "infoDF[['Speed_Scaled', 'Time_Scaled']] = scaler.fit_transform(infoDF[['Speed_Per_Hour', 'Time_Driving']])\n",
    "\n",
    "# 결과 확인\n",
    "print(infoDF[['Speed_Per_Hour', 'Speed_Scaled', 'Time_Driving', 'Time_Scaled']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68529f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Address 컬럼에서 행정동 추출 (보통 마지막 단어)\n",
    "infoDF['행정동'] = infoDF['Address'].str.split().str[-1]\n",
    "\n",
    "# 2. 행정동 컬럼에 대해 원-핫 인코딩 수행\n",
    "one_hot_df = pd.get_dummies(infoDF['행정동'], prefix='동')\n",
    "\n",
    "# 3. infoDF에 인코딩된 컬럼 붙이기\n",
    "infoDF = pd.concat([infoDF, one_hot_df], axis=1)\n",
    "\n",
    "# 결과 확인\n",
    "print(infoDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac5042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. X, y 정의\n",
    "X = infoDF.drop(columns=['Time_Driving'])  # 특성\n",
    "y = infoDF['Time_Driving']                # 타겟\n",
    "\n",
    "# 2. 훈련/검증 데이터 분할 (80:20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. StandardScaler 적용\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. 결과를 DataFrame으로 정리 (원래 컬럼명 유지)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
    "\n",
    "# 5. 데이터 병합 (스케일된 X와 원래 y)\n",
    "DataScaled_train = pd.concat([X_train_scaled_df, y_train], axis=1)\n",
    "DataScaled_test = pd.concat([X_test_scaled_df, y_test], axis=1)\n",
    "\n",
    "# 선택적으로 전체 스케일된 데이터를 합쳐 하나의 DataScaled로 만들 수도 있음\n",
    "DataScaled = pd.concat([DataScaled_train, DataScaled_test])\n",
    "\n",
    "# 결과 확인\n",
    "print(DataScaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 피처(X)와 타겟(y) 분리\n",
    "X = infoDF.drop(columns=['Time_Driving'])\n",
    "y = infoDF['Time_Driving']\n",
    "\n",
    "# 2. 학습/검증 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. 모델 정의 및 학습\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. 예측\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 5. 성능 평가 (RMSE)\n",
    "dt_rmse = np.sqrt(mean_squared_error(y_test, dt_pred))\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "\n",
    "print(f\"Decision Tree RMSE: {dt_rmse:.2f}\")\n",
    "print(f\"Random Forest RMSE: {rf_rmse:.2f}\")\n",
    "\n",
    "# 6. 예측 결과 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 의사결정나무\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, dt_pred, alpha=0.5)\n",
    "plt.xlabel(\"Actual Time_Driving\")\n",
    "plt.ylabel(\"Predicted (Decision Tree)\")\n",
    "plt.title(\"Decision Tree Prediction vs Actual\")\n",
    "\n",
    "# 랜덤포레스트\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, rf_pred, alpha=0.5)\n",
    "plt.xlabel(\"Actual Time_Driving\")\n",
    "plt.ylabel(\"Predicted (Random Forest)\")\n",
    "plt.title(\"Random Forest Prediction vs Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 1. MAE 계산\n",
    "dt_mae = mean_absolute_error(y_test, dt_pred)\n",
    "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
    "\n",
    "# 2. 결과 출력\n",
    "print(f\"Decision Tree MAE: {dt_mae:.2f}\")\n",
    "print(f\"Random Forest MAE: {rf_mae:.2f}\")\n",
    "\n",
    "# 3. 간단한 해석\n",
    "if dt_mae < rf_mae:\n",
    "    print(\"👉 의사결정나무 모델의 MAE가 더 낮으므로 더 정확한 예측을 수행했습니다.\")\n",
    "elif rf_mae < dt_mae:\n",
    "    print(\"👉 랜덤포레스트 모델의 MAE가 더 낮으므로 더 정확한 예측을 수행했습니다.\")\n",
    "else:\n",
    "    print(\"👉 두 모델의 MAE가 동일하거나 거의 비슷합니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ab75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 모델 구성\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(X_train.shape[1],), activation='relu'),  # 입력층 + 은닉층1\n",
    "    Dense(32, activation='relu'),                                    # 은닉층2\n",
    "    Dense(1)                                                         # 출력층 (회귀 문제)\n",
    "])\n",
    "\n",
    "# 2. 모델 컴파일\n",
    "model.compile(\n",
    "    loss='mae',                        # 손실 함수: MAE\n",
    "    optimizer='adam',                 # 최적화 도구: Adam\n",
    "    metrics=['mae', 'mse']            # 평가지표: MAE, MSE\n",
    ")\n",
    "\n",
    "# 3. 학습 수행\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4. 학습 결과 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 손실(Loss)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss (MAE)')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss (MAE)')\n",
    "plt.title('Loss (MAE)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Train MAE')\n",
    "plt.plot(history.history['val_mae'], label='Val MAE')\n",
    "plt.title('Mean Absolute Error (MAE)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb335436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MSE 시각화\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['mse'], label='Train MSE')\n",
    "plt.plot(history.history['val_mse'], label='Validation MSE')\n",
    "plt.title('Model MSE Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
